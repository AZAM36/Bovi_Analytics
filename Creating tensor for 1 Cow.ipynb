{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "641f9bcf-c0b1-4947-8b98-4a50fe722711",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> ###Loading Complete Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "013be853-fcca-44b2-9bc9-050961b650c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "spark.sparkContext.hadoopConfiguration.set(\n",
    "  \"fs.azure.account.key.bovianalytics.blob.core.windows.net\",\n",
    "  \"JTG4AW2TT0WwlzNtX7tQ28fgqFt/w76st4N/pA0PyzW7RJ8yOwV0oyD9JcSnoIGc8k8yOKOPJSGX+ASt8ejJFw==\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fb3b351-a0c8-4cb3-99e1-1569e150a581",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Container name and file path\n",
    "container_name = \"gpluse-cluster-2\"\n",
    "storage_account_name = \"bovianalytics\"\n",
    "file_path_complete = \"Projects/SenseOfSensors/ParquetData/SensorAndCalvingDataRepartitioned02042021/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d411ff6-b227-407a-b970-afeaf23c0d3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Listing files in Storage path\n",
    "display(dbutils.fs.ls(f\"wasbs://{container_name}@{storage_account_name}.blob.core.windows.net/{file_path_complete}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e26239ff-cbad-43bc-87ae-57cd868fa215",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Displaying the Dataset\n",
    "df = spark.read.parquet(f\"wasbs://{container_name}@{storage_account_name}.blob.core.windows.net/{file_path_complete}\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b529ad6-cbda-4495-9c9c-796891d25b18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Loading finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2eb395fd-81c3-4fe3-813e-596a59b52fc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> ###Preprocessing Dataset and removing unnecessary Columns & Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "088a95c6-8dba-432b-ae19-82eba4997a12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Keep only the required columns from the dataset\n",
    "required_columns = [\"AnimalIdentifier\", \"TransitionAnimalEartag\", \"HerdIdentifier\", \"EventDate\", \"ObservationValue\", \"ObservationType\", \"TransitionDaysInMilk\", \"TransitionCalvingDate\", \"TransitionLactationNumber\", \"TransitionParity\", \"TransitionSeason\"]\n",
    "\n",
    "df_processed = df.select(required_columns)\n",
    "\n",
    "display (df_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "560302dd-1d99-47a1-a80d-0816481b8616",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Keep only \"PerDay\", \"Per2Hrs\" in OservationType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e759d7f-1c02-443d-a80a-65531f585a86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Keep only rows where ObservationType is \"MinutesPerDay\" and \"MinutesPer2Hours\"\n",
    "df_processed_observations = df_processed.filter(\n",
    "    col(\"ObservationType\").rlike(\"PerDay$|Per2Hours$\")\n",
    ")\n",
    "\n",
    "display(df_processed_observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1792cf7-b07f-4503-8ae3-0f111adae851",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> ###Checking unique values for \"ObservationType\" Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0baae25-fed8-4356-9056-e96f2ee90f41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Show all distinct values in ObservationType column\n",
    "display(df_processed_observations.select(\"ObservationType\").distinct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2750e8fd-971e-4e9f-ad0a-93b33dc74c1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# For %Per2Hours\n",
    "df_processed_observations.filter(col(\"ObservationType\").endswith(\"Per2Hours\")) \\\n",
    "         .select(\"ObservationType\") \\\n",
    "         .distinct() \\\n",
    "         .orderBy(\"ObservationType\") \\\n",
    "         .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "426b13e0-c294-4f11-9e75-68685c4d61a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# For %PerDay\n",
    "df_processed_observations.filter(col(\"ObservationType\").endswith(\"PerDay\")) \\\n",
    "         .select(\"ObservationType\") \\\n",
    "         .distinct() \\\n",
    "         .orderBy(\"ObservationType\") \\\n",
    "         .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48ef53db-2fca-4aaf-aaea-8ce8cc45ba34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Removing undesired Rows from \"ObservationType\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdfed0e3-622f-469c-8cd8-9f3414812f52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Removing more ObservationType \n",
    "types_to_remove = [\"EatingNumberOfBoutsPerDay\", \"InactiveBoutLengthMinutesPerDay\", \"InactiveBoutsPerDay\", \"InactiveInterboutLengthMinutesPerDay\", \"LyingBoutLengthLowerQntMinutesPerDay\", \"LyingBoutLengthMaxMinutesPerDay\", \"LyingBoutLengthMedMinutesPerDay\", \"LyingBoutLengthMinMinutesPerDay\", \"LyingBoutLengthMinutesPerDay\", \"LyingBoutLengthUpperQntMinutesPerDay\", \"LyingBoutsPerDay\", \"RuminationNumberOfBoutsPerDay\", \"StandupsPerDay\" ]\n",
    "\n",
    "# Filter out those unwanted observation types\n",
    "df_cleaned = df_processed_observations.filter(~col(\"ObservationType\").isin(types_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7a2aef6-446f-45e7-83de-6773afa8bb5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# For %PerDay\n",
    "df_cleaned.filter(col(\"ObservationType\").endswith(\"PerDay\")) \\\n",
    "         .select(\"ObservationType\") \\\n",
    "         .distinct() \\\n",
    "         .orderBy(\"ObservationType\") \\\n",
    "         .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce72c894-3ed7-4e9f-8a04-4856823ecf9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> ###Checking for Null Values of each column Seprately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74c4c7a2-6d2f-4222-8d26-0e62c98f3d61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum as spark_sum, when\n",
    "\n",
    "# Loop through each column and print null counts\n",
    "for column_name in df_cleaned.columns:\n",
    "    null_count = df_cleaned.select(\n",
    "        spark_sum(when(col(column_name).isNull(), 1).otherwise(0)).alias(\"nulls\")\n",
    "    ).collect()[0][\"nulls\"]\n",
    "    \n",
    "    print(f\"Column '{column_name}' has {null_count} null values.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65e371fc-60cb-45d2-83d9-83986c401303",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Checking total number of Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4fba62b-5f60-4c61-8699-c047cae6d586",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count total number of rows in the dataset\n",
    "row_count = df_cleaned.count()\n",
    "print(f\"Total number of rows: {row_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2702d3f-a7ac-4888-b9f6-12890e70896d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Frequency Check - Checking if each \"AnimalIdentifier\" maps to one and only one \"TranisitonAnimalEartag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d60b558e-c39d-47ce-aaae-6d0054c960f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, countDistinct\n",
    "\n",
    "# Group by AnimalIdentifier and count distinct TransitionAnimalEartag for each\n",
    "ambiguous_mapping = df_cleaned.groupBy(\"AnimalIdentifier\") \\\n",
    "    .agg(countDistinct(\"TransitionAnimalEartag\").alias(\"distinct_eartag_count\")) \\\n",
    "    .filter(col(\"distinct_eartag_count\") > 1)\n",
    "\n",
    "# Display AnimalIdentifiers with ambiguous mappings (more than one possible eartag)\n",
    "display(ambiguous_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dce6bf68-a42e-4a0e-8a60-747edd473aac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> ###Removing Rows with \"TranistionAnimalEartag\" = NULL\n",
    "\n",
    "> We only have 0.001% Null values removing them will not effect the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a8ec219-3e19-4d8f-809a-f2dadbc6c69f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop rows with null TransitionAnimalEartag\n",
    "df_final = df_cleaned.filter(col(\"TransitionAnimalEartag\").isNotNull())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f9f2956-8e15-4900-ab04-59922dd37e8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Dataset is ready for 3D sensor - df_final is the finalized dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fed3de44-037a-4837-bbc1-9e0e0c4c3685",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> ###Creating a 3D tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d4ea0a5-7d22-4ceb-bf0b-7576611155c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Filtering a Single Cow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e23d66be-8c52-4a8b-a329-d7f06f4a8cf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Identify 1 unique cows\n",
    "unique_cows = df_final.select(\"TransitionAnimalEartag\").distinct().limit(1)\n",
    "\n",
    "# Join to filter full dataset to those 1 cow\n",
    "df_sampled = df_final.join(unique_cows, on=\"TransitionAnimalEartag\", how=\"inner\")\n",
    "\n",
    "# Verify\n",
    "df_sampled.select(\"TransitionAnimalEartag\").distinct().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ccd7b85-b59c-4386-9246-97078ecb25dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Filtering \"TransitionDaysInMilk\" days from -21 to 305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7ff62f6-95bd-449f-855b-e9f7952459ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Filter days in the valid range [-21, 305]\n",
    "df_sampled_filtered = df_sampled.filter(\n",
    "    (col(\"TransitionDaysInMilk\") >= -21) & (col(\"TransitionDaysInMilk\") <= 305)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fae93fd8-e608-455e-b2e6-af78e964c7a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Spilliting the Dataset %PerDay and %Per2Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc40ef43-b1c9-4b72-a414-0e44400052fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter %PerDay observation types\n",
    "per_day_df = df_sampled_filtered.filter(col(\"ObservationType\").like(\"%PerDay\"))\n",
    "\n",
    "# Filter %Per2Hours observation types\n",
    "per_2hr_df = df_sampled_filtered.filter(col(\"ObservationType\").like(\"%Per2Hours\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4be0d750-e373-4c89-aaf5-30c4b6cfac7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Pivoting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70833e66-2c66-4df8-afed-4828288f667e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, first\n",
    "\n",
    "# Cast 'ObservationValue' to float for both subsets\n",
    "per_day_df = per_day_df.withColumn(\"ObservationValue\", col(\"ObservationValue\").cast(\"float\"))\n",
    "per_2hr_df = per_2hr_df.withColumn(\"ObservationValue\", col(\"ObservationValue\").cast(\"float\"))\n",
    "\n",
    "# Pivot PerDay subset\n",
    "pivot_per_day = per_day_df.groupBy(\"TransitionAnimalEartag\", \"TransitionDaysInMilk\")\\\n",
    "    .pivot(\"ObservationType\")\\\n",
    "    .agg(first(\"ObservationValue\"))\n",
    "\n",
    "# Pivot Per2Hours subset\n",
    "pivot_per_2hours = per_2hr_df.groupBy(\"TransitionAnimalEartag\", \"TransitionDaysInMilk\")\\\n",
    "    .pivot(\"ObservationType\")\\\n",
    "    .agg(first(\"ObservationValue\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3dd8e88a-2de3-4666-ba7a-a85afa0856e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Joining the Pivotted Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1031d8e9-e998-4af7-8e8b-562dd849e43f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join pivoted PerDay and Per2Hours tables\n",
    "joined_pivot = pivot_per_day.alias(\"day\").join(\n",
    "    pivot_per_2hours.alias(\"hr\"),\n",
    "    on=[\"TransitionAnimalEartag\", \"TransitionDaysInMilk\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "display(joined_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc6c37c2-c613-4896-8d81-91455b00116a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get columns lists\n",
    "per_day_cols = [col for col in pivot_per_day.columns if col not in [\"TransitionAnimalEartag\", \"TransitionDaysInMilk\"]]\n",
    "per_2hr_cols = [col for col in pivot_per_2hours.columns if col not in [\"TransitionAnimalEartag\", \"TransitionDaysInMilk\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad29ebb1-a1fd-4b8c-b4d5-a343b3a0ea81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Collect and sort Days\n",
    "# Filter for one cow (in case more got in later)\n",
    "cow_id = joined_pivot.select(\"TransitionAnimalEartag\").first()[\"TransitionAnimalEartag\"]\n",
    "\n",
    "# Filter and sort by day\n",
    "cow_df_sorted = joined_pivot.filter(col(\"TransitionAnimalEartag\") == cow_id)\\\n",
    "                            .orderBy(\"TransitionDaysInMilk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5e20541-e3d4-4d1a-9e26-14c1984fcd95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e991c34f-20bc-48f5-ae73-22000fbb2d00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Build a 3D tensor\n",
    "import numpy as np\n",
    "\n",
    "# Convert to local rows\n",
    "rows = cow_df_sorted.collect()\n",
    "tensor = []\n",
    "\n",
    "for row in rows:\n",
    "    per_day_vec = [row[col] for col in per_day_cols]\n",
    "    per_2hr_vec = [row[col] for col in per_2hr_cols]\n",
    "\n",
    "    if None in per_day_vec or None in per_2hr_vec:\n",
    "        matrix = np.zeros((7, 7)).tolist()\n",
    "    else:\n",
    "        matrix = np.outer(per_day_vec, per_2hr_vec).tolist()\n",
    "\n",
    "    tensor.append(matrix)\n",
    "\n",
    "# Final tensor shape: [T, 7, 7]\n",
    "print(f\" Built tensor with shape: [{len(tensor)}, 7, 7]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f2e1bb63-ce9e-4112-af05-337755b0d85d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Displaying Tensor Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b6d29ff-decc-4fae-8d00-aff4d28f6eb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check basic shape\n",
    "print(f\"Tensor shape: {len(tensor)} days × 7 × 7\")\n",
    "\n",
    "# Check type and dimensions of one sample\n",
    "print(\"Sample matrix shape:\", np.array(tensor[0]).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21a8ed87-0b9d-44ab-935f-8bfa4be318f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Preview the first 3 day-matrices\n",
    "for i, matrix in enumerate(tensor[:3]):\n",
    "    print(f\"\\nDay {i+1} (TransitionDaysInMilk):\")\n",
    "    for row in matrix:\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ac92fe7-5694-4c17-844d-da920127216e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check how many matrices are all zeros\n",
    "zero_matrices = sum(1 for m in tensor if np.sum(m) == 0.0)\n",
    "print(f\"⚠️ Zero-filled matrices: {zero_matrices} / {len(tensor)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "778c4b85-60b3-4b9d-90ce-7f31e30291fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Normalizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d479665-64c9-42eb-a4cc-945ddcca1000",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Normalize each matrix to range [0, 1]\n",
    "normalized_tensor = []\n",
    "\n",
    "for matrix in tensor:\n",
    "    np_matrix = np.array(matrix)\n",
    "    min_val = np_matrix.min()\n",
    "    max_val = np_matrix.max()\n",
    "    \n",
    "    if max_val > min_val: \n",
    "        norm_matrix = (np_matrix - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        norm_matrix = np.zeros_like(np_matrix)  \n",
    "\n",
    "    normalized_tensor.append(norm_matrix.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb21d69c-ce7d-4bf0-9dfd-c0365ae93de7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Displaying Normalized values\n",
    "for i, matrix in enumerate(normalized_tensor[:2]):\n",
    "    print(f\"\\nDay {i+1} (normalized):\")\n",
    "    for row in matrix:\n",
    "        print([round(val, 3) for val in row])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e34b446c-5a46-4301-b135-e3c57bd45350",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> ###Saving .tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7462c66-b66f-4e60-b332-4e55bf8333dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Flatten normalized tensor\n",
    "flat_tensor = [value for matrix in normalized_tensor for row in matrix for value in row]\n",
    "\n",
    "# Create tf.train.Example\n",
    "example = tf.train.Example(features=tf.train.Features(feature={\n",
    "    \"tensor\": tf.train.Feature(float_list=tf.train.FloatList(value=flat_tensor)),\n",
    "    \"tensor_shape\": tf.train.Feature(int64_list=tf.train.Int64List(value=[len(normalized_tensor), 7, 7]))\n",
    "}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75a03bdf-68f3-4b1a-868a-17977b28bca8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Output path in DBFS\n",
    "output_path = \"/dbfs/tmp/BehaviorTFRecords_CowOne/cow_1.tfrecord\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "import os\n",
    "os.makedirs(\"/dbfs/tmp/BehaviorTFRecords_CowOne/\", exist_ok=True)\n",
    "\n",
    "# Write TFRecord\n",
    "with tf.io.TFRecordWriter(output_path) as writer:\n",
    "    writer.write(example.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "011ff7d6-3509-4e46-891b-9617b28a9e7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"dbfs:/tmp/BehaviorTFRecords_CowOne/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34a2d5d0-3a30-471d-b835-6ebf08bd19bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Copy from DBFS to WASBS\n",
    "dbutils.fs.cp(\n",
    "    \"dbfs:/tmp/BehaviorTFRecords_CowOne/cow_1.tfrecord\",\n",
    "    f\"wasbs://{container_name}@{storage_account_name}.blob.core.windows.net/Projects/MuhammadAzam/BehaviorTFRecords_CowOne/cow_1.tfrecord\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a46ecbf-4402-4cc4-b548-27a73d4d8eb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(f\"wasbs://{container_name}@{storage_account_name}.blob.core.windows.net/Projects/MuhammadAzam/BehaviorTFRecords_CowOne/\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d116e5e-0d45-426f-99bb-f758e1606589",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Loading tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfda3a4f-eb46-4787-8be9-c6cb57fb8957",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the TFRecord dataset\n",
    "tfrecord_path = \"/dbfs/tmp/BehaviorTFRecords_CowOne/cow_1.tfrecord\"\n",
    "raw_dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "\n",
    "#  Check if any records exist\n",
    "for raw_record in raw_dataset.take(1):\n",
    "    print(\" Raw record found:\", raw_record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76333b44-7d80-4094-9b01-682ccc12a8a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Total flattened values:\", len(flat_tensor))  # flat_tensor from earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8f3c86a-3d2c-4799-b819-77a4d4c3cc3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# flattened length\n",
    "feature_description = {\n",
    "    \"tensor\": tf.io.FixedLenFeature([16023], tf.float32),\n",
    "    \"tensor_shape\": tf.io.FixedLenFeature([3], tf.int64)\n",
    "}\n",
    "\n",
    "# Reload the TFRecord file\n",
    "tfrecord_path = \"/dbfs/tmp/BehaviorTFRecords_CowOne/cow_1.tfrecord\"\n",
    "raw_dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "\n",
    "# Parse and reshape the tensor\n",
    "for raw_record in raw_dataset.take(1):\n",
    "    parsed = tf.io.parse_single_example(raw_record, feature_description)\n",
    "    shape = parsed[\"tensor_shape\"]\n",
    "    tensor = tf.reshape(parsed[\"tensor\"], shape)\n",
    "\n",
    "    print(\" Parsed tensor shape:\", tensor.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a86bfb02-2453-40af-a36c-e7f7f4236a19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Displaying Reloaded tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4a9f7f7-106f-4616-967b-f6ac1099bcec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# TFRecord path\n",
    "tfrecord_path = \"/dbfs/tmp/BehaviorTFRecords_CowOne/cow_1.tfrecord\"\n",
    "\n",
    "# Define parser\n",
    "def parse_fn(example_proto):\n",
    "    feature_description = {\n",
    "        \"tensor\": tf.io.FixedLenFeature([16023], tf.float32),\n",
    "        \"tensor_shape\": tf.io.FixedLenFeature([3], tf.int64)\n",
    "    }\n",
    "    parsed = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    tensor = tf.reshape(parsed[\"tensor\"], parsed[\"tensor_shape\"])\n",
    "    return tensor\n",
    "\n",
    "# Load and parse dataset\n",
    "parsed_ds = tf.data.TFRecordDataset(tfrecord_path).map(parse_fn)\n",
    "\n",
    "# Display first 3 day matrices from first tensor\n",
    "for tensor in parsed_ds.take(1):\n",
    "    tf.print(\" Full tensor shape:\", tf.shape(tensor))\n",
    "    tf.print(\"\\nDay 1 matrix:\\n\", tensor[0])\n",
    "    tf.print(\"\\nDay 2 matrix:\\n\", tensor[1])\n",
    "    tf.print(\"\\nDay 3 matrix:\\n\", tensor[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94369b48-0a20-415a-90aa-da869a36eb90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Removing Extra Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "422978e5-b4e6-4f32-82f2-c119c48424b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List all files and subfolders under 'Projects/MuhammadAzam/'\n",
    "base_path = f\"wasbs://{container_name}@{storage_account_name}.blob.core.windows.net/Projects/MuhammadAzam/\"\n",
    "all_paths = dbutils.fs.ls(base_path)\n",
    "\n",
    "# Delete each file/subfolder inside the directory\n",
    "for path in all_paths:\n",
    "    dbutils.fs.rm(path.path, recurse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00d1d658-2f73-4965-87b0-19e7c230eb79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_path = f\"wasbs://{container_name}@{storage_account_name}.blob.core.windows.net/Projects/MuhammadAzam\"\n",
    "contents = dbutils.fs.ls(base_path)\n",
    "\n",
    "# Only display if not empty\n",
    "if contents:\n",
    "    display(contents)\n",
    "else:\n",
    "    print(\" Folder is empty — ready for TFRecord export.\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Creating tensor for 1 Cow",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
